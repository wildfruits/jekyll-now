Applying different constraints to a problem changes its potential range of outcomes. The behavior of a closed autonomous system such as a vehicle can be recalibrated by correcting for bias and introducing variance into its preprogrammed inputs, such as through voice commands transmitted through already-calibrated devices. Input to a device such as a smartphone that detects alcohol content on the userâ€™s breath can be used to limit the range of movement of the vehicle being driven. Too much variance in a closed system will overfit that system.

Navigating and driving a vehicle requires bias toward protecting the safety of the driver and passengers at the expense of finding the shortest or fastest route. One should not attempt to drive and navigate at the same time. Constraining the range of motion of the vehicle provides a clearer path to safer navigation and driving.

Having navigated to a location, a driving agent should not have too many sources of competing information in its decision-making process. One source of dysfunctional driving in humans is the entering of a compulsion loop, in which a person takes too many cues at a time from their environment. 

Alcohol and speed are two known variables in determining whether a crash will happen. The day of the week is another important factor, likely because that affects whether drivers are likely to drive while impaired. 
In a car that does not have a human driver, alcohol- and speed-related impairments are not factors. The problem becomes one of predicting accidents that are often less predictable, such as those involving falling objects. 

A key factor in preventing accidents in all cases is the awareness of the driver in the likelihood that they will be involved in an accident (the stress level of the driver). Depending on this, the driver might adjust their driving speed, etc. to compensate for their conditions. Weather and road conditions such as rain or ice on roads are other known contributors to traffic accidents. 

In the case of a car without a human driver, one can imagine it adjusting to long-term variables such as weather and icy roads, but in order to be able to predict and to prevent an accident involving a falling object, it appears the vehicle needs to do real-time risk assessment. Such assessment is likely to need to be preventive and to make use of existing data as much as possible.

(While it appears the vehicle needs to do real-time risk assessment, such assessment is likely to actually need to be preventive and to make use of existing data as much as possible. The vehicle should not have to encounter falling objects multiple times in order to learn how to react to them.)

One significant problem with falling objects is that while incidents involving them are rare, they are so severe and relevant as to not be realistically ignored or attributed to error or anomalies in data. For this reason, knowing when such eventualities have occurred in the past seems the most useful source of information in predicting when they will happen again. Unlike incidents due to road conditions, in which cases a driving agent can gradually adjust to the conditions and needs less preventive planning, incidents involving falling objects happen fast and require immediate reaction time.  




 


